{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPLICATION OF SECOND CHAPTER SIMULATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"Insert directory here\"\n",
    "data_dir = os.path.join(base_dir, 'First_Application_Data')\n",
    "text_files = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(base_dir, 'CountryZip.zip'), 'r') as myzip:\n",
    "    myzip.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthonormalise a matrix via the Gram-Schmidt process\n",
    "def gram_schmidt_process(columns):\n",
    "    num_columns = columns.shape[1]\n",
    "    orthonormal_columns = np.zeros((columns.shape[0], num_columns))\n",
    "    for i in range(num_columns):\n",
    "        v = columns.iloc[:, i]\n",
    "        for j in range(i):\n",
    "            v -= np.dot(v, orthonormal_columns[:, j]) * orthonormal_columns[:, j]\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm > 0:\n",
    "            orthonormal_columns[:, i] = v / norm       \n",
    "    return pd.DataFrame(orthonormal_columns, columns = columns.columns)\n",
    "\n",
    "# Calculate the two-stage least squares estimator\n",
    "def two_stage_least_squares(X, y, Z):\n",
    "    Pi2sls = np.linalg.lstsq(Z, X, rcond = None)[0]\n",
    "    X2sls = (Z@Pi2sls).reshape(-1, 1)\n",
    "    v2sls = X - Z @ Pi2sls\n",
    "    b2sls = np.linalg.lstsq(X2sls, y, rcond = None)[0]\n",
    "    u2sls = y - X * b2sls\n",
    "    return b2sls, u2sls, X2sls, v2sls\n",
    "\n",
    "# Calculate the minimum eigenvalue for the limited information maximum likelihood estimator\n",
    "def fun_min_eig(W, Z, n):\n",
    "    sigw = (W.T @ W) / n\n",
    "    sigw12 = scipy.linalg.sqrtm(sigw)\n",
    "    wpzw = (W.T @ Z) @ (np.linalg.lstsq(Z, W, rcond = None)[0])\n",
    "    eig_mat = np.linalg.inv(sigw12) @ wpzw @ np.linalg.inv(sigw12) / n\n",
    "    return np.linalg.eigvals(eig_mat).min()\n",
    "\n",
    "# Calculate the limited information maximum likelihood estimator\n",
    "def limited_information_maximum_likelihood(X, Z, W, X2sls, n):\n",
    "    min_eig = fun_min_eig(W, Z, n)\n",
    "    bliml = ((X2sls.T @ y - min_eig * (X.T @ y))) / ((X2sls.T @ X - min_eig * (X.T @ X)))\n",
    "    uliml = (y - X * bliml).reshape(-1, 1)\n",
    "    Muliml = np.identity(n) - (uliml @ (np.linalg.inv(uliml.T @ uliml)) @ uliml.T)\n",
    "    Piliml = (np.linalg.inv(Z.T @ Muliml @ Z)) @ (Z.T @ Muliml @ X)\n",
    "    Xliml = (Z @ Piliml).reshape(-1, 1)\n",
    "    return bliml, uliml, Xliml\n",
    "\n",
    "# Calculate the heteroskedasticity-robust score statistic\n",
    "def fun_score(Z, xhat, uhat):\n",
    "    Z2 = Z[:,1:]\n",
    "    mxz = Z2 - (xhat @ (np.linalg.lstsq(xhat, Z2, rcond = None)[0]))\n",
    "    variance = mxz.T @ (np.diagflat(uhat * uhat)) @ mxz\n",
    "    return uhat.T @ mxz @ (np.linalg.inv(variance)) @ mxz.T @ uhat\n",
    "\n",
    "# Calculate the Newey-West heteroskedasticity-autocorrelation-robust variance estimator\n",
    "def newey_west(e, X, L):\n",
    "    N, k = X.shape[0], X.shape[1] \n",
    "    Q = np.zeros((k, k))\n",
    "    for l in range(L + 1):\n",
    "        w_l = 1 - l / (L + 1)\n",
    "        for t in range(l + 1, N):\n",
    "            if l == 0:\n",
    "                Q += e[t] ** 2 * np.outer(X[t, :], X[t, :])\n",
    "            else:\n",
    "                Q += w_l * e[t] * e[t - l] * (np.outer(X[t, :], X[t - l, :]) + np.outer(X[t - l, :], X[t, :]))\n",
    "    return Q\n",
    "\n",
    "# Calculate the heteroskedasticity-autocorrelation-robust score statistic   \n",
    "def fun_score_newey_west(Z, xhat, uhat, n, lags):\n",
    "    Z2 = Z[:,1:]\n",
    "    mxz = Z2 - xhat @ (np.linalg.lstsq(xhat, Z2, rcond = None)[0])\n",
    "    variance = newey_west(uhat, mxz, lags)\n",
    "    return uhat.T @ mxz @ (np.linalg.inv(variance)) @ mxz.T @ uhat\n",
    "\n",
    "# Calculate the effective F statistic and effective degrees of freedom\n",
    "def effective_F(X, Z, vhat, lags):\n",
    "    Fweight = newey_west(vhat, Z, lags)\n",
    "    Fweight_tr = np.trace(Fweight)\n",
    "    eff = (X.T @ Z @ Z.T @ X) / Fweight_tr\n",
    "    effDOF = ((Fweight_tr ** 2) * 21) / ((np.trace(Fweight.T @ Fweight)) + 20 * Fweight_tr * np.max(np.linalg.eigvals(Fweight)))\n",
    "    return eff, effDOF\n",
    "\n",
    "# Simulate the critical value for the effective F statistic\n",
    "def critical_value(Keff, tau):\n",
    "    np.random.seed(234435)\n",
    "    vals = np.random.noncentral_chisquare(Keff, tau * Keff, 10000000) / Keff  \n",
    "    cv = np.percentile(vals, 95)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUL | F: 19.17, cv: 18.40 2SLS: 0.05, LIML: 0.03, Hansen: 8.71, KP: 8.82\n",
      "CAN | F: 13.82, cv: 18.58 2SLS: -0.30, LIML: -0.34, Hansen: 5.02, KP: 5.03\n",
      "FR  | F: 42.09, cv: 19.33 2SLS: -0.08, LIML: -0.08, Hansen: 0.46, KP: 0.46\n",
      "GER | F: 14.62, cv: 18.60 2SLS: -0.42, LIML: -0.44, Hansen: 2.68, KP: 2.65\n",
      "ITA | F: 21.37, cv: 18.92 2SLS: -0.07, LIML: -0.07, Hansen: 1.1, KP: 1.09\n",
      "JAP | F: 5.48, cv: 21.33 2SLS: -0.04, LIML: -0.05, Hansen: 4.57, KP: 4.58\n",
      "NTH | F: 13.66, cv: 18.41 2SLS: -0.15, LIML: -0.14, Hansen: 3.67, KP: 3.67\n",
      "SWD | F: 21.11, cv: 18.70 2SLS: -0.00, LIML: -0.00, Hansen: 2.58, KP: 2.58\n",
      "SWT | F: 8.12, cv: 18.14 2SLS: -0.49, LIML: -0.50, Hansen: 2.28, KP: 2.29\n",
      "UK  | F: 8.44, cv: 20.12 2SLS: 0.17, LIML: 0.16, Hansen: 5.05, KP: 5.08\n",
      "USA | F: 8.66, cv: 18.67 2SLS: 0.06, LIML: 0.03, Hansen: 7.22, KP: 7.59\n",
      "AUL | F: 2.45, cv: 19.46 2SLS: 0.50, LIML: 30.03, Hansen: 9.49, KP: 8.82\n",
      "CAN | F: 2.96, cv: 18.10 2SLS: -1.04, LIML: -2.98, Hansen: 6.97, KP: 5.03\n",
      "FR  | F: 0.22, cv: 19.69 2SLS: -3.12, LIML: -12.38, Hansen: 2.14, KP: 0.46\n",
      "GER | F: 1.28, cv: 20.16 2SLS: -1.05, LIML: -2.29, Hansen: 2.98, KP: 2.65\n",
      "ITA | F: 0.49, cv: 18.89 2SLS: -3.34, LIML: -14.81, Hansen: 3.99, KP: 1.09\n",
      "JAP | F: 2.00, cv: 17.89 2SLS: -0.18, LIML: -21.56, Hansen: 8.42, KP: 4.58\n",
      "NTH | F: 1.87, cv: 18.94 2SLS: -0.53, LIML: -6.94, Hansen: 10.18, KP: 3.67\n",
      "SWD | F: 0.90, cv: 17.31 2SLS: -0.10, LIML: -399.86, Hansen: 13.27, KP: 2.58\n",
      "SWT | F: 1.62, cv: 20.00 2SLS: -1.56, LIML: -2.00, Hansen: 2.95, KP: 2.29\n",
      "UK  | F: 2.68, cv: 17.63 2SLS: 1.06, LIML: 6.21, Hansen: 8.17, KP: 5.08\n",
      "USA | F: 2.85, cv: 18.01 2SLS: 0.68, LIML: 34.11, Hansen: 11.82, KP: 7.59\n"
     ]
    }
   ],
   "source": [
    "text_file_count = len(text_files)\n",
    "\n",
    "table_header = ['Country', 'F', 'cv', '2SLS', 'LIML', 'J', 'KP']\n",
    "\n",
    "table1 = pd.DataFrame(columns = table_header)\n",
    "table2 = pd.DataFrame(columns = table_header)\n",
    "\n",
    "for table in range(1,3):\n",
    "\n",
    "    for country_number in range(0, text_file_count):\n",
    "\n",
    "        original_df = pd.read_csv(os.path.join(data_dir, os.listdir(data_dir)[country_number]))\n",
    "\n",
    "        column_name = original_df.columns[0]\n",
    "\n",
    "        new_column_names = original_df.columns[0].split(\"\\t\")\n",
    "        joined_data = original_df.values\n",
    "\n",
    "        new_data = []\n",
    "\n",
    "        for row in range(original_df.shape[0]):\n",
    "            joined_data = original_df.iloc[row, 0]\n",
    "            data_list = joined_data.split(\"\\t\")\n",
    "            \n",
    "            row_data = {column_name: value for column_name, value in zip(new_column_names, data_list)}\n",
    "\n",
    "            new_data.append(row_data)\n",
    "\n",
    "        df = pd.DataFrame(new_data)\n",
    "        df[new_column_names[0]] = df[new_column_names[0]].apply(pd.to_datetime, errors = 'coerce')\n",
    "        df[new_column_names[1:]] = df[new_column_names[1:]].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "        df = df.iloc[2:]\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        if country_number < 10:\n",
    "            lags = 4\n",
    "        else:\n",
    "            lags = 6\n",
    "\n",
    "        obs = len(df)\n",
    "        onevec = np.ones((obs, 1))\n",
    "        M = np.identity(obs) - (onevec @ onevec.T) /obs\n",
    "\n",
    "        model_vars = ['dc', 'rr', 'rrf', 'z1', 'z2', 'z3', 'z4']\n",
    "        new_model_vars = [var.upper() for var in model_vars]\n",
    "\n",
    "        df[new_model_vars] = df[model_vars].apply(lambda x: M @ x)\n",
    "\n",
    "        df[new_model_vars[-4:]] = gram_schmidt_process(df[new_model_vars[-4:]])\n",
    "        df[new_model_vars[-4:]] = df[new_model_vars[-4:]] * np.sqrt(obs)\n",
    "\n",
    "        country_name = text_files[country_number][:-5]\n",
    "        if len(country_name) == 3:\n",
    "            pass\n",
    "        else:\n",
    "            country_name = ''.join([country_name, ' '])\n",
    "\n",
    "        if table == 1:\n",
    "            y = df['DC'].values\n",
    "            X = df['RRF'].values\n",
    "            Z = df[new_model_vars[-4:]].values\n",
    "            W = df[['DC', 'RRF']].values\n",
    "\n",
    "            tsls_mat = two_stage_least_squares(X, y, Z)\n",
    "            liml_mat = limited_information_maximum_likelihood(X, Z, W, tsls_mat[2], obs)\n",
    "            hansen = np.round(fun_score_newey_west(Z, tsls_mat[2], tsls_mat[1], obs, lags),2)\n",
    "            kp = np.round(fun_score_newey_west(Z, liml_mat[2], liml_mat[1], obs, lags),2)    \n",
    "\n",
    "            eff, effDOF =  effective_F(X, Z, tsls_mat[3], lags)\n",
    "            cv = critical_value(effDOF, 10)\n",
    "\n",
    "            new_row_table = pd.DataFrame({'Country': [country_name], 'F': [eff], 'cv': [cv], '2SLS': [tsls_mat[0][0]], 'LIML': [liml_mat[0][0]], 'J': [hansen], 'KP': [kp][0][0]})\n",
    "            table1 = pd.concat([table1, new_row_table], ignore_index = True)\n",
    "\n",
    "        else:\n",
    "            y = df['RRF'].values\n",
    "            X = df['DC'].values\n",
    "            Z = df[new_model_vars[-4:]].values\n",
    "            W = df[['RRF', 'DC']].values\n",
    "\n",
    "            tsls_mat = two_stage_least_squares(X, y, Z)\n",
    "            liml_mat = limited_information_maximum_likelihood(X, Z, W, tsls_mat[2], obs)\n",
    "            hansen = np.round(fun_score_newey_west(Z,tsls_mat[2], tsls_mat[1], obs, lags),2)\n",
    "            kp = np.round(fun_score_newey_west(Z, liml_mat[2], liml_mat[1], obs, lags),2)    \n",
    "\n",
    "            eff, effDOF =  effective_F(X, Z, tsls_mat[3], lags)\n",
    "            cv = critical_value(effDOF, 10)\n",
    "\n",
    "            new_row_table = pd.DataFrame({'Country': [country_name], 'F': [eff], 'cv': [cv], '2SLS': [tsls_mat[0][0]], 'LIML': [liml_mat[0][0]], 'J': [hansen], 'KP': [kp][0][0]})\n",
    "            table2 = pd.concat([table2, new_row_table], ignore_index = True)\n",
    "\n",
    "        print(f\"{country_name} | F: {eff:.2f}, cv: {cv:.2f} 2SLS: {tsls_mat[0][0]:.2f}, LIML: {liml_mat[0][0]:.2f}, Hansen: {hansen}, KP: {kp[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>F</th>\n",
       "      <th>cv</th>\n",
       "      <th>2SLS</th>\n",
       "      <th>LIML</th>\n",
       "      <th>J</th>\n",
       "      <th>KP</th>\n",
       "      <th>Country</th>\n",
       "      <th>F</th>\n",
       "      <th>cv</th>\n",
       "      <th>2SLS</th>\n",
       "      <th>LIML</th>\n",
       "      <th>J</th>\n",
       "      <th>KP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUL</td>\n",
       "      <td>19.17</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.82</td>\n",
       "      <td>AUL</td>\n",
       "      <td>2.45</td>\n",
       "      <td>19.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30.03</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAN</td>\n",
       "      <td>13.82</td>\n",
       "      <td>18.58</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.03</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>18.10</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-2.98</td>\n",
       "      <td>6.97</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>42.09</td>\n",
       "      <td>19.33</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.22</td>\n",
       "      <td>19.69</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-12.38</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GER</td>\n",
       "      <td>14.62</td>\n",
       "      <td>18.60</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.65</td>\n",
       "      <td>GER</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.16</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITA</td>\n",
       "      <td>21.37</td>\n",
       "      <td>18.92</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.09</td>\n",
       "      <td>ITA</td>\n",
       "      <td>0.49</td>\n",
       "      <td>18.89</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-14.81</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JAP</td>\n",
       "      <td>5.48</td>\n",
       "      <td>21.33</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.58</td>\n",
       "      <td>JAP</td>\n",
       "      <td>2.00</td>\n",
       "      <td>17.89</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-21.56</td>\n",
       "      <td>8.42</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NTH</td>\n",
       "      <td>13.66</td>\n",
       "      <td>18.41</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>NTH</td>\n",
       "      <td>1.87</td>\n",
       "      <td>18.94</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>10.18</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SWD</td>\n",
       "      <td>21.11</td>\n",
       "      <td>18.70</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>SWD</td>\n",
       "      <td>0.90</td>\n",
       "      <td>17.31</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-399.86</td>\n",
       "      <td>13.27</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SWT</td>\n",
       "      <td>8.12</td>\n",
       "      <td>18.14</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>SWT</td>\n",
       "      <td>1.62</td>\n",
       "      <td>20.00</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UK</td>\n",
       "      <td>8.44</td>\n",
       "      <td>20.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.08</td>\n",
       "      <td>UK</td>\n",
       "      <td>2.68</td>\n",
       "      <td>17.63</td>\n",
       "      <td>1.06</td>\n",
       "      <td>6.21</td>\n",
       "      <td>8.17</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>8.66</td>\n",
       "      <td>18.67</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.59</td>\n",
       "      <td>USA</td>\n",
       "      <td>2.85</td>\n",
       "      <td>18.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>34.11</td>\n",
       "      <td>11.82</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country      F     cv  2SLS  LIML     J    KP Country     F     cv  2SLS  \\\n",
       "0      AUL  19.17  18.40  0.05  0.03  8.71  8.82     AUL  2.45  19.46  0.50   \n",
       "1      CAN  13.82  18.58 -0.30 -0.34  5.02  5.03     CAN  2.96  18.10 -1.04   \n",
       "2      FR   42.09  19.33 -0.08 -0.08  0.46  0.46     FR   0.22  19.69 -3.12   \n",
       "3      GER  14.62  18.60 -0.42 -0.44  2.68  2.65     GER  1.28  20.16 -1.05   \n",
       "4      ITA  21.37  18.92 -0.07 -0.07  1.10  1.09     ITA  0.49  18.89 -3.34   \n",
       "5      JAP   5.48  21.33 -0.04 -0.05  4.57  4.58     JAP  2.00  17.89 -0.18   \n",
       "6      NTH  13.66  18.41 -0.15 -0.14  3.67  3.67     NTH  1.87  18.94 -0.53   \n",
       "7      SWD  21.11  18.70 -0.00 -0.00  2.58  2.58     SWD  0.90  17.31 -0.10   \n",
       "8      SWT   8.12  18.14 -0.49 -0.50  2.28  2.29     SWT  1.62  20.00 -1.56   \n",
       "9      UK    8.44  20.12  0.17  0.16  5.05  5.08     UK   2.68  17.63  1.06   \n",
       "10     USA   8.66  18.67  0.06  0.03  7.22  7.59     USA  2.85  18.01  0.68   \n",
       "\n",
       "      LIML      J    KP  \n",
       "0    30.03   9.49  8.82  \n",
       "1    -2.98   6.97  5.03  \n",
       "2   -12.38   2.14  0.46  \n",
       "3    -2.29   2.98  2.65  \n",
       "4   -14.81   3.99  1.09  \n",
       "5   -21.56   8.42  4.58  \n",
       "6    -6.94  10.18  3.67  \n",
       "7  -399.86  13.27  2.58  \n",
       "8    -2.00   2.95  2.29  \n",
       "9     6.21   8.17  5.08  \n",
       "10   34.11  11.82  7.59  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.concat([table1, table2], axis = 1)\n",
    "full_results = full_results.round(2)\n",
    "full_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
